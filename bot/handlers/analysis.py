# bot/handlers/analysis.py

import pandas as pd
import matplotlib.pyplot as plt

from pathlib import Path
from collections import Counter

from aiogram import types
from aiogram.filters.command import Command
from aiogram.types import ContentType, FSInputFile

from .commands import dp

# -------------------------------------------------------------------
# –ü—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º —Å –¥–∞–Ω–Ω—ã–º–∏
# -------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).resolve().parents[2]
CSV_DIR     = PROJECT_ROOT / "marketplace_data" / "csv"
REPORTS_DIR = PROJECT_ROOT / "marketplace_data" / "reports"
CSV_DIR.mkdir(parents=True, exist_ok=True)
REPORTS_DIR.mkdir(parents=True, exist_ok=True)

# –ü—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
_last_uploaded: Path | None = None


def load_last_dataframe() -> pd.DataFrame | None:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç DataFrame –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–∏—Å–ª–∞–Ω–Ω–æ–≥–æ –∏–ª–∏ —Å–∞–º–æ–≥–æ —Å–≤–µ–∂–µ–≥–æ —Ñ–∞–π–ª–∞."""
    global _last_uploaded
    if _last_uploaded and _last_uploaded.exists():
        try:
            return (
                pd.read_excel(_last_uploaded, sheet_name=0)
                if _last_uploaded.suffix.lower() == ".xlsx"
                else pd.read_csv(_last_uploaded)
            )
        except Exception:
            return None

    # fallback: —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ
    files = list(CSV_DIR.glob("*.xlsx")) + list(CSV_DIR.glob("*.csv"))
    if not files:
        return None
    last = max(files, key=lambda f: f.stat().st_mtime)
    try:
        return pd.read_excel(last, sheet_name=0) if last.suffix.lower() == ".xlsx" else pd.read_csv(last)
    except Exception:
        return None


@dp.callback_query(lambda c: c.data == 'analyze_prices')
async def handle_analyze_prices(callback_query: types.CallbackQuery):
    await callback_query.message.answer(
        "üõ† –ü—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX –∏, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ, —Å—Ä–∞–∑—É —É–∫–∞–∂–∏—Ç–µ –≤ –ø–æ–¥–ø–∏—Å–∏ –∫–æ–º–∞–Ω–¥—É:\n"
        "  /summary  ¬†‚Äî –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª–µ–π\n"
        "  /price_hist‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω\n"
        "  /discount ¬†‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–∏–¥–æ–∫\n"
        "  /chars    ¬†‚Äî —Ç–æ–ø‚Äë15 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n"
        "  /compare  ¬†‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n"
        "  /margin   ¬†‚Äî –º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n"
        "  /flow     ¬†‚Äî –¥–∏–Ω–∞–º–∏–∫–∞ –æ—Ç–∑—ã–≤–æ–≤"
    )
    await callback_query.answer()


@dp.message(lambda m: m.content_type == ContentType.DOCUMENT)
async def handle_file_upload(message: types.Message):
    global _last_uploaded
    doc = message.document
    ext = Path(doc.file_name or "").suffix.lower()
    if ext not in (".csv", ".xlsx"):
        return await message.reply("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ .csv –∏ .xlsx")
    dest = CSV_DIR / f"{doc.file_id}{ext}"
    tg_file = await message.bot.get_file(doc.file_id)
    await message.bot.download_file(tg_file.file_path, destination=dest)
    _last_uploaded = dest
    await message.reply(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ `{dest.name}`", parse_mode="Markdown")

    # –µ—Å–ª–∏ —Å—Ä–∞–∑—É –≤ –ø–æ–¥–ø–∏—Å–∏ –∫–æ–º–∞–Ω–¥–∞ ‚Äî –≤—ã–ø–æ–ª–Ω—è–µ–º
    if message.caption:
        cmd = message.caption.strip().split()[0].lower()
        mapping = {
            "/summary": cmd_summary_report,
            "/price_hist": cmd_price_distribution,
            "/discount": cmd_discount_analysis,
            "/chars": cmd_characteristics_freq,
            "/compare": cmd_compare,
            "/margin": cmd_margin,
            "/flow": cmd_flow,
        }
        if cmd in mapping:
            await mapping[cmd](message)


@dp.message(Command("summary"))
async def cmd_summary_report(message: types.Message):
    df = load_last_dataframe()
    if df is None:
        return await message.reply("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX.")
    total = len(df)
    miss = lambda col: df[col].isna().sum() / total * 100 if col in df else 0
    stats = {
        "–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫": total,
        "% –±–µ–∑ final_price": miss("final_price"),
        "% –±–µ–∑ wallet_price": miss("wallet_price"),
        "% –±–µ–∑ old_price": miss("old_price"),
        "% –±–µ–∑ price_history": miss("price_history"),
        "% –±–µ–∑ rating": miss("rating"),
        "% –±–µ–∑ reviews": miss("reviews"),
    }
    text = "\n".join(f"{k}: {v:.1f}¬†%" for k, v in stats.items())
    await message.reply(f"üìä *–°–≤–æ–¥–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º*\n\n{text}", parse_mode="Markdown")


@dp.message(Command("price_hist"))
async def cmd_price_distribution(message: types.Message):
    df = load_last_dataframe()
    if df is None or "price_clean" not in df:
        return await message.reply("‚ùå –ù–µ—Ç –ø–æ–ª—è price_clean.")
    df["price_clean"].dropna().hist(bins=30)
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω")
    plt.xlabel("–¶–µ–Ω–∞"); plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞"); plt.grid(alpha=0.3)
    out = REPORTS_DIR / "price_hist.png"
    plt.tight_layout(); plt.savefig(out); plt.close()
    await message.reply_photo(FSInputFile(path=out), caption="üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω")


@dp.message(Command("discount"))
async def cmd_discount_analysis(message: types.Message):
    df = load_last_dataframe()
    if df is None:
        return await message.reply("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
    df = df.copy()
    df["old_num"]   = pd.to_numeric(df.get("old_price", ""), errors="coerce")
    df["final_num"] = pd.to_numeric(df.get("final_price", ""), errors="coerce")
    df["discount_pct"] = (df["old_num"] - df["final_num"]) / df["old_num"] * 100
    df["discount_pct"].dropna().hist(bins=30)
    plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–∏–¥–æ–∫ (%)")
    plt.xlabel("–°–∫–∏–¥–∫–∞, %"); plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞"); plt.grid(alpha=0.3)
    out = REPORTS_DIR / "discounts.png"
    plt.tight_layout(); plt.savefig(out); plt.close()
    await message.reply_photo(FSInputFile(path=out), caption="üí∏ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–∏–¥–æ–∫")


@dp.message(Command("chars"))
async def cmd_characteristics_freq(message: types.Message):
    df = load_last_dataframe()
    if df is None or "characteristics_parsed" not in df:
        return await message.reply("‚ùå –ù–µ—Ç –ø–æ–ª—è characteristics_parsed.")
    counter = Counter()
    for props in df["characteristics_parsed"].dropna():
        if isinstance(props, dict):
            counter.update(props.keys())
    text = "\n".join(f"{k}: {v}" for k, v in counter.most_common(15))
    await message.reply(f"üìã *–¢–æ–ø‚Äë15 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫*\n\n{text}", parse_mode="Markdown")


@dp.message(Command("compare"))
async def cmd_compare(message: types.Message):
    df = load_last_dataframe()
    if df is None or "category" not in df or "price_clean" not in df:
        return await message.reply("‚ùå –¢—Ä–µ–±—É—é—Ç—Å—è –ø–æ–ª—è category –∏ price_clean.")
    top5 = df.groupby("category")["price_clean"].mean().nlargest(5)
    lines = [f"{i+1}. {cat[:30]}‚Ä¶ ‚Äî {val:.2f}" for i, (cat, val) in enumerate(top5.items())]
    await message.reply("üè∑ *–¢–æ–ø‚Äë5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω–µ:*\n\n" + "\n".join(lines),
                        parse_mode="Markdown")


@dp.message(Command("margin"))
async def cmd_margin(message: types.Message):
    df = load_last_dataframe()
    if df is None or "cost" not in df or "price_clean" not in df:
        return await message.reply("‚ùå –¢—Ä–µ–±—É—é—Ç—Å—è –ø–æ–ª—è cost –∏ price_clean.")
    df = df.copy()
    df["margin_pct"] = (df["price_clean"] - pd.to_numeric(df["cost"], errors="coerce")) / df["price_clean"] * 100
    df["margin_pct"].dropna().hist(bins=30)
    plt.title("–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å (%)")
    plt.xlabel("–ú–∞—Ä–∂–∞ %"); plt.ylabel("–ß–∞—Å—Ç–æ—Ç–∞"); plt.grid(alpha=0.3)
    out = REPORTS_DIR / "margin.png"
    plt.tight_layout(); plt.savefig(out); plt.close()
    await message.reply_photo(FSInputFile(path=out), caption="üìä –ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å")


@dp.message(Command("flow"))
async def cmd_flow(message: types.Message):
    df = load_last_dataframe()
    if df is None or "reviews" not in df or "parsed_at" not in df:
        return await message.reply("‚ùå –¢—Ä–µ–±—É—é—Ç—Å—è –ø–æ–ª—è reviews –∏ parsed_at.")
    df = df.copy()
    df["date"] = pd.to_datetime(df["parsed_at"], errors="coerce").dt.date
    daily = df.groupby("date")["reviews"].sum()
    plt.figure(figsize=(8, 4))
    daily.plot(marker="o")
    plt.title("–î–∏–Ω–∞–º–∏–∫–∞ –æ—Ç–∑—ã–≤–æ–≤"); plt.xlabel("–î–∞—Ç–∞"); plt.ylabel("–°—É–º–º–∞ reviews"); plt.grid(alpha=0.3)
    out = REPORTS_DIR / "flow.png"
    plt.tight_layout(); plt.savefig(out); plt.close()
    await message.reply_photo(FSInputFile(path=out), caption="üìà –î–∏–Ω–∞–º–∏–∫–∞ –æ—Ç–∑—ã–≤–æ–≤")
